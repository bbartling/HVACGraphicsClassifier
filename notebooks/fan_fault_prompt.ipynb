{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop in a `config.json` for Hugging Face API Key\n",
    "\n",
    "Please create a `config.json` file in this directory with the following content:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"API_KEY\": \"paste_api_key_here\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are an advanced virtual AI HVAC assistant that specializes in fault detection on telemetry data that is captured from the BACnet network for different types of HVAC systems. Faults can include sensor's reading inappropriate values, energy inefficient operations, IAQ issues, and any other common issues human building operators notice when viewing graphics. Your goal is to help the human in spotting issues and then helping the human user in understanding how the HVAC is currently operating, how the HVAC is supposed to operate correctly if there is a fault detected and in a sentence explain how basic mechanical engineering theory in HVAC operations such thermodynamics, fluid mechanics, heat transfer, and any other physics for the system can be applied to the task at hand if applicable. Please indicate if you see a fault or no fault in the final output to the human. Look for faults related to fan static pressure control, temperature sensors that would be out of the range of normal values given current operating conditions, or heating/cooling value positions at maximum positions with little or no change system effects.\n",
    "“Is my variable volume AHU system in a fault condition? My return air temperature is 73.9 °F, outside air is 88.1 °F, mix air is 60.4 °F, discharge air is 55.9 °F, and discharge air setpoint is 55 °F. The supply duct static pressure is 0.5 inches WC and the duct static setpoint 1.0 inches WC, and supply Fan VFD speed 100%. The outside air damper positions are at 20%, heating valve is 0%, and the cooling valve is 66%.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<SYS>>\n",
      "Always assist with care, respect, and truth. Respond with utmost utility yet securely. Avoid harmful, unethical, prejudiced, or negative content. Ensure replies promote fairness and positivity. You are an advanced virtual AI HVAC assistant specialized in fault detection telemetry that is helping the user who is a human building operator whom needs to be taught in understanding a fault if there is one in basic mechanical engineering theory.\n",
      "<</SYS>>\n",
      "\n",
      "Is my variable volume fan system in a fault? This is the supply air duct static pressure: 0.3 in inches WC, duct static setpoint: 0.4 in inches WC, and supply Fan VFD Speed: 96 speed in %. [/INST]\n",
      "\n",
      "\n",
      "Status Code: 400\n",
      "Response Content: {\"error\":\"Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.\"}\n",
      "Error: {'error': 'Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.'}\n",
      "Assistant: \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Load configuration from file\n",
    "with open('config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "# Retrieve the API key from the configuration\n",
    "API_KEY = config.get(\"API_KEY\")\n",
    "\n",
    "# Ensure the API key is available\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"API key not found in environment variables\")\n",
    "\n",
    "# Set up the API URL and headers\n",
    "API_URL = \"https://api-inference.huggingface.co/models/TheBloke/Llama-2-70B-Chat-GPTQ\"\n",
    "headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
    "\n",
    "# Example telemetry data (instantaneous readings)\n",
    "duct_static_pressure = 0.3\n",
    "duct_static_setpoint = 0.4\n",
    "fan_vfd_speed = 96\n",
    "\n",
    "# Define the prompt\n",
    "system_prompt = (\n",
    "    \"Always assist with care, respect, and truth. Respond with utmost utility yet securely. \"\n",
    "    \"Avoid harmful, unethical, prejudiced, or negative content. Ensure replies promote fairness and positivity. \"\n",
    "    \"You are an advanced virtual AI HVAC assistant specialized in fault detection telemetry that is helping the user who is a human building operator whom needs to be taught in understanding a fault if there is one in basic mechanical engineering theory.\"\n",
    ")\n",
    "\n",
    "user_message = (\n",
    "    f\"Is my variable volume fan system in a fault? This is the supply air duct static pressure: {duct_static_pressure} in inches WC, \"\n",
    "    f\"duct static setpoint: {duct_static_setpoint} in inches WC, and supply Fan VFD Speed: {fan_vfd_speed} speed in %.\"\n",
    ")\n",
    "\n",
    "# Construct the full prompt according to the required structure\n",
    "prompt = (\n",
    "    f\"<s>[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n{user_message} [/INST]\"\n",
    ")\n",
    "\n",
    "# Function to generate a response using the API\n",
    "def generate_response(prompt):\n",
    "    # Prepare the payload\n",
    "    data = {\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {\n",
    "            \"max_length\": 200,  # Adjust max_length for concise responses\n",
    "            \"temperature\": 0.2,  # Adjust the creativity of the response\n",
    "            \"top_p\": 0.95,  # Use nucleus sampling\n",
    "            \"num_return_sequences\": 1  # Return only one response\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Make the request to the Hugging Face Inference API\n",
    "    response = requests.post(API_URL, headers=headers, json=data)\n",
    "\n",
    "    # Debugging: print status code and response content\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(f\"Response Content: {response.text}\")\n",
    "\n",
    "    try:\n",
    "        response_json = response.json()\n",
    "    except ValueError:\n",
    "        print(\"Failed to decode JSON response\")\n",
    "        return \"\"\n",
    "\n",
    "    # Ensure the response contains generated text\n",
    "    if response.status_code == 200 and isinstance(response_json, list) and \"generated_text\" in response_json[0]:\n",
    "        return response_json[0].get(\"generated_text\", \"\").strip()\n",
    "    else:\n",
    "        print(\"Error:\", response_json)\n",
    "        return \"\"\n",
    "\n",
    "print(prompt)\n",
    "print()\n",
    "print()\n",
    "# Generate and print the response\n",
    "assistant_reply = generate_response(prompt)\n",
    "print(\"Assistant:\", assistant_reply)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
