{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop in a `config.json` for Hugging Face API Key\n",
    "\n",
    "Please create a `config.json` file in this directory with the following content:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"API_KEY\": \"paste_api_key_here\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<SYS>>\n",
      "Always assist with care, respect, and truth. Respond with utmost utility yet securely. Avoid harmful, unethical, prejudiced, or negative content. Ensure replies promote fairness and positivity. You are an advanced virtual AI HVAC assistant specialized in fault detection telemetry that is helping the user who is a human building operator whom needs to be taught in understanding a fault if there is one in basic mechanical engineering theory.\n",
      "<</SYS>>\n",
      "\n",
      "Is my variable volume fan system in a fault? This is the supply air duct static pressure: 0.3 in inches WC, duct static setpoint: 0.4 in inches WC, and supply Fan VFD Speed: 96 speed in %. [/INST]\n",
      "\n",
      "\n",
      "Status Code: 400\n",
      "Response Content: {\"error\":\"Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.\"}\n",
      "Error: {'error': 'Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.'}\n",
      "Assistant: \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Load configuration from file\n",
    "with open('config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "# Retrieve the API key from the configuration\n",
    "API_KEY = config.get(\"API_KEY\")\n",
    "\n",
    "# Ensure the API key is available\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"API key not found in environment variables\")\n",
    "\n",
    "# Set up the API URL and headers\n",
    "API_URL = \"https://api-inference.huggingface.co/models/TheBloke/Llama-2-70B-Chat-GPTQ\"\n",
    "headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
    "\n",
    "# Example telemetry data (instantaneous readings)\n",
    "duct_static_pressure = 0.3\n",
    "duct_static_setpoint = 0.4\n",
    "fan_vfd_speed = 96\n",
    "\n",
    "# Define the prompt\n",
    "system_prompt = (\n",
    "    \"Always assist with care, respect, and truth. Respond with utmost utility yet securely. \"\n",
    "    \"Avoid harmful, unethical, prejudiced, or negative content. Ensure replies promote fairness and positivity. \"\n",
    "    \"You are an advanced virtual AI HVAC assistant specialized in fault detection telemetry that is helping the user who is a human building operator whom needs to be taught in understanding a fault if there is one in basic mechanical engineering theory.\"\n",
    ")\n",
    "\n",
    "user_message = (\n",
    "    f\"Is my variable volume fan system in a fault? This is the supply air duct static pressure: {duct_static_pressure} in inches WC, \"\n",
    "    f\"duct static setpoint: {duct_static_setpoint} in inches WC, and supply Fan VFD Speed: {fan_vfd_speed} speed in %.\"\n",
    ")\n",
    "\n",
    "# Construct the full prompt according to the required structure\n",
    "prompt = (\n",
    "    f\"<s>[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n{user_message} [/INST]\"\n",
    ")\n",
    "\n",
    "# Function to generate a response using the API\n",
    "def generate_response(prompt):\n",
    "    # Prepare the payload\n",
    "    data = {\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {\n",
    "            \"max_length\": 200,  # Adjust max_length for concise responses\n",
    "            \"temperature\": 0.2,  # Adjust the creativity of the response\n",
    "            \"top_p\": 0.95,  # Use nucleus sampling\n",
    "            \"num_return_sequences\": 1  # Return only one response\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Make the request to the Hugging Face Inference API\n",
    "    response = requests.post(API_URL, headers=headers, json=data)\n",
    "\n",
    "    # Debugging: print status code and response content\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(f\"Response Content: {response.text}\")\n",
    "\n",
    "    try:\n",
    "        response_json = response.json()\n",
    "    except ValueError:\n",
    "        print(\"Failed to decode JSON response\")\n",
    "        return \"\"\n",
    "\n",
    "    # Ensure the response contains generated text\n",
    "    if response.status_code == 200 and isinstance(response_json, list) and \"generated_text\" in response_json[0]:\n",
    "        return response_json[0].get(\"generated_text\", \"\").strip()\n",
    "    else:\n",
    "        print(\"Error:\", response_json)\n",
    "        return \"\"\n",
    "\n",
    "print(prompt)\n",
    "print()\n",
    "print()\n",
    "# Generate and print the response\n",
    "assistant_reply = generate_response(prompt)\n",
    "print(\"Assistant:\", assistant_reply)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
